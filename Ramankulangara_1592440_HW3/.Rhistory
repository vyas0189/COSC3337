-4.136 (8)+  104.219
-4.136* (8)+  104.219
dbinom(10:12,15prob = .80)
dbinom(10:12,15,prob = .80)
sum(dbinom(10:12,15,prob = .80))
pbinom(11,15,.80)
dbinom(11,15,.80)
x = (10/30) + (2 * (14/30)) + (3 * (18/30)) + (4 * (22/30))
x
y = (15/30) + (2* (20/30))+ (3 * 25/30)
y
choose(3,1)/choose(15,9)
choose(3,0) * choose(15,3)/choose(15,9)
(choose(3,0) * choose(15,3))/choose(15,9)
(choose(3,1) * choose(15,3))/choose(15,9)
(choose(3,1) * choose(12,9))/choose(15,9)
(choose(3,0) * choose(12,9))/choose(15,9)
(choose(3,1) * choose(3,15))/choose(15,9)
(choose(3,0) * choose(12,9))/choose(15,9)
1 - ((choose(3,0) * choose(12,9))/choose(15,9))
.4*.2
sqrt(12.2)
x = c(4,7,9,11,14,17)
y = c(93,77,66,61,49,34)
plot(x,y)
lm(y ~ x)
cor(x,y)
(cor(x,y))^2
( -4.371 * 9)+108.503
66 - 69.164
1 - ((choose(7,0) * choose(10,9))/choose(17,9) )
dbinom(10:12, 15,.8)
sum(dbinom(10:12, 15,.8))
1/ .392
((.475)* (0.099))/((0.392)* (.475) * (0.099))
1 -((.475)* (0.099))/((0.392)* (.475) * (0.099))
((.5 * .95) + (0.1 * .01))/((0.4 * 0.98)+ (.5 * 0.95) + (0.99))
((0.4 * 0.98)+ (.5 * 0.95) + (0.99))
((0.4 * 0.98)
h
(0.4 * 0.98)
(.5 * 0.95)
((0.4 * 0.98)+ (.5 * 0.95) + (.1 * 0.99))
((.5 * 0.95) + (.1 * 0.99))/((0.4 * 0.98)+ (.5 * 0.95) + (.1 * 0.99))
lm(y~x)
ppois(2,.6)
choose(8,1)/choose(9,1)
choose(13,3)/choose(56,3)
(choose(43,2) * choose(13,1))/choose(56,3)
.22 + .04 + .04
.08 + .04 + .22
.34 -1
1 - (1/25 1/50 + 2/25 + 1/50)
1 - (1/25+ 1/50 + 2/25 + 1/50)
((1/5) * 450 ) + ((4/5) * 250)
(10 * (1/20)) + (50 * (1/10)) + (100 * (33/40))
(100 * (1/20)) + (2500 * (1/10)) + (10000 * (33/40))
(100 * (1/20)) + (2500 * (1/10)) + (10000 * (33/40))
(10 * (1/20)) + (50 * (1/10)) + (100 * (33/40))
(100 * (1/20)) + (2500 * (1/10)) + (10000 * (33/40))
8505 - (88)^2
x = c(4,6,11,13,17,19)
y = c(23,29,27,42,26,41)
cor(x,y)
x = c(5,5,11,12,15,19)
y = c(41,37,28,21,17,14)
lm(y ~x)
3(4) + 23
3 * (4) + 23
x = c(1,2,3,4,5,6)
y  c(13,19,17,31,17,34)
y = c(13,19,17,31,17,34)
plot(x, resid(lm(y~x)))
mean(32,34,40,43,44,47,48,49,49,49,50,51,51,52,53,54,55,61,62,65,66,66,70,71,92)
median(32,34,40,43,44,47,48,49,49,49,50,51,51,52,53,54,55,61,62,65,66,66,70,71,92)
pbinom(1,21,.008)
ppois(3,6) - ppois(3,2)
1 - dbinom(20,.5,2)
dbinom(20,.5,2)
dbinom(20,2,.5)
.15/(.1 + .15 + .05)
.05/(.05 + .05 + .05)
(3 * -1 * .3) + (3 * 1 * .05) + (5 * -1 * .05) + (7 * -1 * .15) + (7 * 1 * .15)
1- pexp(7,1/6)
pexp(3, 1/4) - pexp(2, 1/7)
pexp(3, 1/4) - pexp(2, 1/4)
1- pexp(8,1/6)
pexp(6, 1/4) - pexp(3, 1/4)
1- pexp(5,1/3)
qnorm((1+.97)/2)
27.5 + 2.19009 + (4/sqrt(49))
27.5 + 2.19009 * (4/sqrt(49))
27.5 - 2.19009 * (4/sqrt(49))
33+47
qnorm(1.99/2)
21 + 21 + 20 + 15 + 15 + 14
21/106
17/115
21/106
qnorm(1.99/2)
2.575829 * sqrt((0.1981132(1 - 0.1981132))/106)
2.575829 * sqrt((0.1981132*(1 - 0.1981132))/106)
(21/106) + 0.09971887
(21/106) - 0.09971887
qnorm(1.85/2)
1.439531 * sqrt((.49 * (1- .49))/100)
.49 -0.07196215
.49  + 0.07196215
qnorm(1.9/2)
(.62 - .5)/(sqrt((.5 * .5)/100))
stick = c(25.9, 26.5,25.6,26.4,25.4,25.9)
liquid = c(16.4, 16.9, 17.7, 16.6, 17.5, 16.7)
mean(stick)
sd(stick)
mean(liquid)
sd(liquid)
(25.95 - 16.96667)/(sqrt((0.432435 ^ 2)/6) + ( 0.5202563 ^ 2)/ 6)
(25.95 - 16.96667)/(sqrt((0.432435 ^ 2)/6) + (( 0.5202563 ^ 2)/ 6))
stick = c(25.9,26.5,25.6,26.4,25.4,25.9)
liquid = c(16.4,16.9,17.7,16.6,17.5,16.7)
mean(stick)
sd(stick)
mean(liquid)
sd(liquid)
220/18.71
(72.5-70)/(16.1 / sqrt(45))
2 * pt(1.04,44)
2 * pt(-abs(1.04, 44))
2 * pt(-abs(1.04), 44))
2 * pt(-abs(1.04), 44)
f = function(x) exp((-1/5)*x )
integrate(f,0, Inf)
(30 * 0.6561)/(qchisq(0.035,30, lower.tail = F))
sqrt( 0.4330254)
(30 * 0.6561)/(qchisq(0.035,30, lower.tail = T))
sqrt(1.11987)
f = function(x) exp((-1/4) * x)
integrate(f, 12, Inf)
1 - pexp(12,1/4)
f = function(x) 1/5 * exp((-1/4) * x)
integrate(f, 12, Inf)
f = function(x) 1/4 * exp((-1/4) * x)
integrate(f, 12, Inf)
1 - pexp(0,1/4)
12.5 -10.6
1.3/(sqrt(50))
1.9 /  0.1838478
2* (1-pnorm(10.33))
1.9 /  0.1838478
2* (1-pnorm(10.33))
(qnorm(1.98/2)/11 * 70)^2
((qnorm(1.95/2)/ 10) * 80)^2
((qnorm(1.95/2)/ 80) * 10)^2
f = function(x) ((4 * x)/81) * exp((-2*(x)^2)/81)
integrate(f,0,1)
(1/25) * (5/3)^2
pexp(6,1/5) - pexp(4,1/5)
1 - pnorm(74.96, 50, 12)
qnorm(0.57,0,1)
qnorm(0.68,0,1)
1 - pnorm(53,47,10.2/sqrt(25))
qnorm(1-0.68)
p = c(16,21,20,22,14,19,15,17,19,20,17)
m = t.test(p,alternative = "greater", mu = 14)
m
za = qnorm(1.95/2)
.84 + c(-1,1) * za * sqrt((1.84 * .15)/36)
((.10) * (1-.10))/((.12/qnorm(1 - (1-.95)/2))^2)
((.10) * (1 -.10))/ ((.12/qnorm(1-(1-.95)/2))^2)
((.20) * (1 -.20))/ ((.12/qnorm(1-(1-.95)/2))^2)
qnorm(.95,16,2)
x = c(1,8,8,11,16,17)
y = c(21,28,29,41,32,43)
lm(y~x)
x = c(2,8,8,13,16,19)
y = c(22,29,28,40,33,41)
cos(x,y)
coef(x,y)
cor(x,y)
2.6 * 2 + 22.73
30 - 27.73
x = c(1,2,3,4,5,6)
y = c(31,28,16,12,9, 2)
q = lm(y~x)
plot(x, resid(q))
x = c(44.2,42.25,45.5,40.3,39,35.75,37.7)
y = c(1.3,3.25,.65,6.5,5.85,8.45,37.7,6.5)
lm(y~x)
length(y)
y = c(1.3,3.25,.65,6.5,5.85,8.45,6.5)
lm(y~x)
1 - (210/618)
qnorm(.05/2)
qt(-1.959964, 8)
chisq.test(c(6,6,6), p = c(.4,.15,.2,.25))
chisq.test(c(6,6,6,2), p = c(.4,.15,.2,.25))
chisq.test(c(6,6,6,2), p = c(.40,.15,.2,.25))
demo(pf)
demo()
pbinom(3,6,.73)
pnorm(66,75.4,5.2)
x = c(0,1,2,3,4)
p = c(.1,.18,.2,.31,.21)
sum(x * p)
sum(x^2 * p) - sum(x * p)
sum(x^2 * p) - (sum(x * p))^2
0.08/0.43
pbinom(3,6,.73)
pnorm(66,75.4,5.2)
help("pchisq")
(1/50) + (9/100) + (1/20) + (9/100)
1 - .25
(-17 * (1/50)) + (-9 * (9/100)) + (-5 * (1/20)) + (8 * (9/100)) + (13 * (.75))
((10^2 * (1/6)) + (50^2 *(1/3)) + (100^2 * (5/12)))  - ((10 * (1/6)) + (50 * (1/3)) + (100 * (5/12)))^2
1 - ((5/4)^3)/125
f = function(x) 3/125 * x^2
integrate(f,0,5)
qmorm(1 - 0.71)
qnorm(1 - 0.71)
pnorm(127,97,25) - pnorm(67,97,25)
1 - pnorm(54,49, 10.2/sqrt(25) )
p = pnorm(54,49, 10.2/sqrt(25) )
1 - p
1 - pnorm(54,49, 10.1/sqrt(25) )
x = c(16,21,20,22,14,19,19,15,17,19,20.17)
mean(x)
sd(x)
(18.37909)/(2.552021/sqrt(12))
(18.37909 - 14)/(2.552021/sqrt(12))
1 - pt(5.944157,11)
9.4 + c(-1,1) * qt(1.95/2, 18)*sqrt(0.49/19)
(0.62 - 0.5)/sqrt(0.5 * 0.5/100)
2 * (1 - pnorm(2.4))
218/13.47
1 - pf(16.18411,2,15)
(3667 - 3322)/sqrt(((468 ^ 2)/34) + (642 ^ 2)/31)
1 - pt(2.455687, 30)
1 - pt(2.455687, 32)
1 - pt(2.455687, 31)
px = c(.2, .32,.1,.15,.23)
x = c(79,95,32,50,73)
chisq.test(x, p = px)
x = c(2,6,10,13,15,19)
y = c(22,29,26,40,31,44)
lm(y~x)
summary(lm(y~x))
install.packages("cluster")
install.packages("factoextra")
install.packages("fpc")
install.packages("dbscan")
library(cluster)
library(factoextra)
library("fpc")
library("dbscan")
complex8 <- read.csv("Complex8.data", header=FALSE)
dataset <- read.csv("Pima.csv", header = FALSE)
ZPima <- scale(dataset[,1:8])
ZPima <- cbind(ZPima, dataset[,9])
entropyvec <- function(vec) {
s <- sum(vec)
totalh <- Reduce(function(acc, elem) {
prob <- elem / s
h <- if (prob == 0) 0 else prob * log2(prob)
return (acc - h)
}, vec, 0)
return (totalh)
}
entropy <- function(clusterassignment, groundtruth) {
clusterlevels <- clusterassignment
clusterclass <- table(clusterassignment, groundtruth)
n <- nrow(clusterclass)
entropy_weight <- array(dim=c(n, 2))
population <- 0
for (i in 1:n) {
clustersize <- sum(clusterclass[i,])
population <- population + clustersize
entropy_weight[i,] = c(entropyvec(clusterclass[i,]), clustersize)
}
percentage <- 0
outliers <- sum(clusterclass[1,])
entropy_weight[1,] = c(0, 0)
percentage <- outliers / population
population <- population - outliers
totalh <- 0
if (population > 0) {
for (i in 1:n) {
totalh <- totalh + entropy_weight[i, 1] * entropy_weight[i, 2] / population
}
}
return (c(totalh, percentage))
}
a1 <- c(0,1,1,1,1,2,2,3)
a2 <- c('1','1','1','0','0','2','2','2')
b <- c('A','A','A','E','E','D','D','C')
print(entropy(a1, b))
print(entropy(a2, b))
wabs_dist <- function(u,v,w){
return(sum((abs(u-v))*w))
}
wabs_dist(c(1,2), c(4,5), c(0.2,0.3))
wabs_dist(c(4,5),c(9,12), c(0.2,0.3))
create_dm <- function(x,w){
rows <- nrow(x)
data <- matrix(nrow = rows, ncol = rows)
for(i in 1:rows){
for(j in 1:rows){
data[i,j] <- wabs_dist(as.numeric(as.vector(x[i,])), as.numeric(as.vector(x[j,])), w)
data[j,i]=data[i,j];
}
data[i,i] = 0
}
return(data)
}
print(create_dm(data.frame("x" = c(1,4,9), "y" = c(2,5,12)), c(0.2,0.3)))
k6 <- kmeans(ZPima[,1:8], 6 , nstart=20)
k9 <- kmeans(ZPima[,1:8], 9 , nstart=20)
pA <- create_dm(as.data.frame(ZPima[,1:8]), c(1,1,1,1,1,1,1,1))
pB <- create_dm(as.data.frame(ZPima[,1:8]), c(0.2,1,0,0,0,1,0.2,1))
pC <- create_dm(as.data.frame(ZPima[,1:8]), c(0,1,0,0,0,1,0,0))
pamA <- pam(x = pA, k = 6)
pamB <- pam(x = pB, k = 6)
pamC <- pam(x = pC, k = 6)
overall_entropy <- mean(c(
entropy(k6$cluster, ZPima[,9])[1],
entropy(k9$cluster, ZPima[,9])[1],
entropy(pamA$clustering, ZPima[,9])[1],
entropy(pamB$clustering, ZPima[,9])[1],
entropy(pamC$clustering, ZPima[,9])[1])
)
setwd("C:/Users/vyas0/Desktop/UH_CS/COSC3337/HW3")
complex8 <- read.csv("Complex8.data", header=FALSE)
dataset <- read.csv("Pima.csv", header = FALSE)
ZPima <- scale(dataset[,1:8])
ZPima <- cbind(ZPima, dataset[,9])
entropyvec <- function(vec) {
s <- sum(vec)
totalh <- Reduce(function(acc, elem) {
prob <- elem / s
h <- if (prob == 0) 0 else prob * log2(prob)
return (acc - h)
}, vec, 0)
return (totalh)
}
entropy <- function(clusterassignment, groundtruth) {
clusterlevels <- clusterassignment
clusterclass <- table(clusterassignment, groundtruth)
n <- nrow(clusterclass)
entropy_weight <- array(dim=c(n, 2))
population <- 0
for (i in 1:n) {
clustersize <- sum(clusterclass[i,])
population <- population + clustersize
entropy_weight[i,] = c(entropyvec(clusterclass[i,]), clustersize)
}
percentage <- 0
outliers <- sum(clusterclass[1,])
entropy_weight[1,] = c(0, 0)
percentage <- outliers / population
population <- population - outliers
totalh <- 0
if (population > 0) {
for (i in 1:n) {
totalh <- totalh + entropy_weight[i, 1] * entropy_weight[i, 2] / population
}
}
return (c(totalh, percentage))
}
a1 <- c(0,1,1,1,1,2,2,3)
a2 <- c('1','1','1','0','0','2','2','2')
b <- c('A','A','A','E','E','D','D','C')
print(entropy(a1, b))
print(entropy(a2, b))
wabs_dist <- function(u,v,w){
return(sum((abs(u-v))*w))
}
wabs_dist(c(1,2), c(4,5), c(0.2,0.3))
wabs_dist(c(4,5),c(9,12), c(0.2,0.3))
create_dm <- function(x,w){
rows <- nrow(x)
data <- matrix(nrow = rows, ncol = rows)
for(i in 1:rows){
for(j in 1:rows){
data[i,j] <- wabs_dist(as.numeric(as.vector(x[i,])), as.numeric(as.vector(x[j,])), w)
data[j,i]=data[i,j];
}
data[i,i] = 0
}
return(data)
}
print(create_dm(data.frame("x" = c(1,4,9), "y" = c(2,5,12)), c(0.2,0.3)))
k6 <- kmeans(ZPima[,1:8], 6 , nstart=20)
k9 <- kmeans(ZPima[,1:8], 9 , nstart=20)
pA <- create_dm(as.data.frame(ZPima[,1:8]), c(1,1,1,1,1,1,1,1))
pB <- create_dm(as.data.frame(ZPima[,1:8]), c(0.2,1,0,0,0,1,0.2,1))
pC <- create_dm(as.data.frame(ZPima[,1:8]), c(0,1,0,0,0,1,0,0))
pamA <- pam(x = pA, k = 6)
pamB <- pam(x = pB, k = 6)
pamC <- pam(x = pC, k = 6)
overall_entropy <- mean(c(
entropy(k6$cluster, ZPima[,9])[1],
entropy(k9$cluster, ZPima[,9])[1],
entropy(pamA$clustering, ZPima[,9])[1],
entropy(pamB$clustering, ZPima[,9])[1],
entropy(pamC$clustering, ZPima[,9])[1])
)
overall_entropy
entropy(k6$cluster, ZPima[,9])[1]
k6$centers
entropy(k9$cluster, ZPima[,9])[1]
k9$centers
entropy(pamA$clustering, ZPima[,9])[1]
data.frame( Means=rowMeans(as.data.frame(pamA$medoids)))
entropy(pamB$clustering, ZPima[,9])[1]
data.frame( Means=rowMeans(as.data.frame(pamB$medoids)))
entropy(pamC$cluster, ZPima[,9])[1]
data.frame( Means=rowMeans(as.data.frame(pamC$medoids)))
newData <- dataset[,2]
newData <- cbind(newData, dataset[,6])
fviz_cluster(k6,
data = newData,
stand = FALSE,
ellipse.type = "norm",
show.clust.cent = FALSE,
geom = "point",
ggtheme = theme_classic())
fviz_cluster(k9,
data = newData,
stand = FALSE,
ellipse.type = "norm",
show.clust.cent = FALSE,
geom = "point",
ggtheme = theme_classic())
fviz_cluster(pamA,
data = newData,
stand = FALSE,
ellipse.type = "norm",
show.clust.cent = FALSE,
geom = "point",
ggtheme = theme_classic())
fviz_cluster(pamB,
data = newData,
stand = FALSE,
ellipse.type = "norm",
show.clust.cent = FALSE,
geom = "point",
ggtheme = theme_classic())
fviz_cluster(pamC,
data = newData,
stand = FALSE,
ellipse.type = "norm",
show.clust.cent = FALSE,
geom = "point",
ggtheme = theme_classic())
dbscan::kNNdistplot(ZPima[,1:8], k=6)
abline(h =1.9, lty = 2)
db <- fpc::dbscan(ZPima[,1:8], eps = 1.9, MinPts = 3)
newData <- dataset[,2]
newData <- cbind(newData, dataset[,6])
fviz_cluster(db, as.data.frame(newData), geom = "point")
entropy(db$cluster, ZPima[, 9])[1]
ZComplex8 <- scale(complex8[,1:2])
ZComplex8 <- cbind(ZComplex8, complex8[,3])
complex8_k8 <- kmeans(ZComplex8[,1:2], 8, nstart = 20)
complex8_k11 <- kmeans(ZComplex8[,1:2], 11, nstart = 20)
fviz_cluster(complex8_k8,
data = ZComplex8[,1:2],
stand = FALSE,
ellipse = FALSE,
show.clust.cent = FALSE,
geom = "point",
ggtheme = theme_classic())
fviz_cluster(complex8_k11,
data = ZComplex8[,1:2],
stand = FALSE,
ellipse = FALSE,
show.clust.cent = FALSE,
geom = "point",
ggtheme = theme_classic())
cat(entropy(complex8_k8$cluster, complex8$V3)[1], "\n")
cat(entropy(complex8_k11$cluster, complex8$V3)[1])
eps <- c(0.09,0.10,0.13,0.15,0.2,0.25,0.30)
minpts <- c(2,3,4,5,6,7,8)
entropyResult <- c()
outliers <- c()
counter <- 1
for (i in 1:length(eps)){
for(j in 1:length(minpts)){
complexDB <- dbscan(ZComplex8[,1:2], eps=eps[i], minPts = minpts[j])
clusterResult <- complexDB$cluster
en <- entropy(clusterResult, ZComplex8[,3])[1]
entropyResult[counter] <- en
outlierR <- entropy(clusterResult, ZComplex8[,3])[2] * 100
outliers[counter] <- outlierR
counter <- counter + 1
}
}
index <- 1
for(i in 1:length(eps)){
for(j in 1:length(minpts)){
cat("Model# ", index,"using Epsilon=", eps[i], "and minPts=", minpts[j], ": \n",
"Entropy: ",entropyResult[index], ", Outlier Percentage: ", outliers[index], "\n")
index <- index + 1
}
}
complexDB <- dbscan(ZComplex8[,1:2], eps=.1, minPts = 5)
fviz_cluster(complexDB, ZComplex8[,1:2],
stand = FALSE,
ellipse = FALSE,
show.clust.cent = FALSE,
geom = "point",
ggtheme = theme_classic())
entropy(complexDB$cluster, ZComplex8[,3])[1]
